{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3432a657",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5498fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe59229",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ddd2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDF_DIR = Path(\"pdfs\")\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb67410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7ee13",
   "metadata": {},
   "source": [
    "### Document Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "93a5cdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_pdfs(pdf_dir) :\n",
    "    texts = []\n",
    "    for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "        reader = PdfReader(str(pdf_file))\n",
    "        text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "texts = load_pdfs(PDF_DIR)\n",
    "len(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66477d5d",
   "metadata": {},
   "source": [
    "### split to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "facc8029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def split_texts(texts) :\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    chunks = []\n",
    "    for text in texts:\n",
    "        chunks.extend(splitter.split_text(text))\n",
    "    return chunks\n",
    "\n",
    "chunks = split_texts(texts)   \n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4c4b2",
   "metadata": {},
   "source": [
    "### Embeddings with cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8cd3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embeddings = CohereEmbeddings(model=\"embed-multilingual-v3.0\",cohere_api_key=cohere_api_key,  user_agent=\"langchain\")\n",
    "vectors = embeddings.embed_documents(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a48be",
   "metadata": {},
   "source": [
    "### Vector Store with Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c724f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 224}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "pinecone_index = pc.Index(\"my-rag-index\")\n",
    "\n",
    "to_upsert = [\n",
    "    (f\"chunk-{i}\", vec, {\"text\": chunks[i]})\n",
    "    for i, vec in enumerate(vectors)\n",
    "]\n",
    "pinecone_index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224f0f2",
   "metadata": {},
   "source": [
    "\n",
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a86cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rag_pipeline(query: str):\n",
    "    \n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    #Retrieval with Pinecone Query\n",
    "    response = pinecone_index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=4,                \n",
    "    include_metadata=True   \n",
    "    )\n",
    "\n",
    "\n",
    "    for i, match in enumerate(response['matches']):\n",
    "        print(f\"\\n-- 拽注 {i+1} --\")\n",
    "        print(match['metadata']['text'])\n",
    "\n",
    "    #Generation with OpenAI\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai_api_key,\n",
    "        temperature=1.0\n",
    "        )\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        转 转  \n",
    "        注 注 砖  转住住 注 拽砖专 转 .\n",
    "          注 专, 专 \\\" 爪转 注\\\".\n",
    "        拽砖专:\n",
    "        {context}\n",
    "\n",
    "        砖:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "            )\n",
    "    context = \"\\n\\n\".join([match['metadata']['text'] for match in response['matches']])\n",
    "    prompt = prompt_template.format(context=context, question=query)\n",
    "\n",
    "    answer = llm.invoke(prompt)\n",
    "    return answer.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a12a144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- 拽注 1 --\n",
      "砖  住专转  爪专 住.  砖 转 专转 砖 住专转   住驻专 砖拽  \n",
      "  专 转专 转驻专 砖 .  住专转 爪专 注砖转  注 \n",
      "\n",
      "-- 拽注 2 --\n",
      "爪注转 住驻专 注拽专转 驻砖 驻砖专 砖驻专 驻 专 转 爪 住专转, \n",
      "拽  拽专 注 专驻 .   \n",
      "   驻砖 住专转 砖 砖拽  砖 转.\n",
      "\n",
      "-- 拽注 3 --\n",
      "专 拽爪专  住 专转  砖拽注 砖 驻住转 注 拽, 注拽专 驻住转 砖转.   \n",
      "专驻 转 转 住专转  驻 驻住转 砖砖拽注 注 拽, 专转 专砖转 砖  \n",
      "住.\n",
      "\n",
      "-- 拽注 4 --\n",
      "驻专拽5   \n",
      " 专驻 住专转 \n",
      "转专转 砖注转  专转 ?   \n",
      "  砖 专 专驻 住专转?  \n",
      " 住专转    专转?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'注 驻 拽住, 专驻 住专转 转爪注 爪注转 驻 驻住转 (注拽专 砖转) 砖砖拽注 注 拽 专转 专砖转 砖 住.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rag_pipeline(\" 专驻 住专转?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86379573",
   "metadata": {},
   "source": [
    "### Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c20e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- 拽注 1 --\n",
      "砖  住专转  爪专 住.  砖 转 专转 砖 住专转   住驻专 砖拽  \n",
      "  专 转专 转驻专 砖 .  住专转 爪专 注砖转  注 \n",
      "\n",
      "-- 拽注 2 --\n",
      "爪注转 住驻专 注拽专转 驻砖 驻砖专 砖驻专 驻 专 转 爪 住专转, \n",
      "拽  拽专 注 专驻 .   \n",
      "   驻砖 住专转 砖 砖拽  砖 转.\n",
      "\n",
      "-- 拽注 3 --\n",
      "驻砖  住专转  专    砖拽专  住专转    '转转 砖 祝  住 ',  专  砖驻专   \n",
      "转 爪  住专转,   驻 专驻 转,    爪注转  住专转 转转. 砖专  爪 注砖转\n",
      "\n",
      "-- 拽注 4 --\n",
      "专 拽爪专  住 专转  砖拽注 砖 驻住转 注 拽, 注拽专 驻住转 砖转.   \n",
      "专驻 转 转 住专转  驻 驻住转 砖砖拽注 注 拽, 专转 专砖转 砖  \n",
      "住.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def build_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"#  砖转转 注 拽爪 转 (RAG)\")\n",
    "        question = gr.Textbox(label=\"砖\", placeholder=\" 转 注 专 转驻专?\")\n",
    "        answer = gr.Textbox(label=\"转砖\")\n",
    "        submit_btn = gr.Button(\"砖\")\n",
    "        submit_btn.click(fn=run_rag_pipeline, inputs=question, outputs=answer)\n",
    "    return demo\n",
    "\n",
    "demo = build_interface()\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
